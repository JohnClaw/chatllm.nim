# chatllm.nim
Nim api-wrapper for llm-inference chatllm.cpp

V-lang api wrapper for llm-inference chatllm.cpp

All credits go to original repo: https://github.com/foldl/chatllm.cpp and Llama 405b (https://cloud.sambanova.ai/) which made 99% of work. I only guided it with prompts.
